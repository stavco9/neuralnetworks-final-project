# Multimodal Harmful Content Detection in Social Media Memes

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Paper](https://img.shields.io/badge/Paper-Academic%20Report-red.svg)](docs/final_report.pdf)

> **Deep Learning Final Project - Reichman University 2025**  
> *Stav Cohen & Efi Pecani*

An advanced multimodal system for detecting harmful content in social media memes through specialized CNN and text classification architectures with intelligent fusion strategies.

## ğŸ¯ Project Overview

Social media memes combine visual and textual elements to convey complex messages, making them particularly challenging for automated content moderation. This project develops a comprehensive multimodal approach that:

- **Analyzes images and text independently** using specialized neural architectures
- **Combines predictions intelligently** through 8 different fusion strategies  
- **Optimizes for F1-score** to balance precision and recall in harmful content detection
- **Provides explainable results** through attention mechanisms and confidence analysis

### Key Results
- **CNN Performance**: F1-score of 0.51 with balanced precision-recall
- **Best Fusion Strategy**: Aggressive fusion achieving 0.514 F1-score (+0.78% improvement)
- **Novel Architecture**: F1-optimized text classifier with hierarchical attention
- **Comprehensive Evaluation**: Systematic comparison of 8 fusion strategies

### True Positives Examples
![TP](results/comparison_tp_cnn_.png)

## ğŸ—ï¸ System Architecture

```
â”Œâ”€ ğŸ–¼ï¸ Image Component (CNN)
â”‚  â”œâ”€ Architecture: ResNet50-based with gradual unfreezing
â”‚  â”œâ”€ Input: Meme images (OCR text removed)
â”‚  â””â”€ Performance: F1 = 0.51, Precision = 0.56, Recall = 0.46
â”‚
â”œâ”€ ğŸ“ Text Component (F1-Optimized BiLSTM)
â”‚  â”œâ”€ Architecture: BiLSTM + Hierarchical Attention + Multi-features
â”‚  â”œâ”€ Features: LSTM + N-grams + Pattern Recognition + Coded Language
â”‚  â””â”€ Performance: F1 = 0.068 (overfitting challenges identified)
â”‚
â””â”€ ğŸ”„ Multimodal Fusion
   â”œâ”€ 8 Fusion Strategies: Winner-takes-all, Confidence weighting, etc.
   â””â”€ Best Strategy: Aggressive Fusion (F1 = 0.514)
```

## ğŸ“Š Dataset

**Facebook Harmeme Dataset**: 9,000 memes with binary harmful/safe labels
- **Training**: 8,500 samples â†’ 75% train (6,375) + 25% validation (2,125)  
- **Testing**: 500 samples (held out)
- **Evaluation**: 1,000 stratified samples for comprehensive analysis
- **Source**: [HuggingFace Dataset](https://huggingface.co/datasets/George511242/Facebook_harmeme_dataset)

## ğŸš€ Quick Start

### Prerequisites
```bash
# Core requirements
Python >= 3.9
PyTorch >= 2.0
CUDA >= 11.8 (recommended for GPU acceleration)
```

### Installation
```bash
# Clone the repository
git clone https://github.com/stavco9/neuralnetworks-final-project.git
cd neuralnetworks-final-project

# Install dependencies
pip install -r requirements.txt

# Download NLTK data (for text processing)
python -c "import nltk; nltk.download('punkt'); nltk.download('wordnet'); nltk.download('stopwords')"
```

### Dataset Setup
```bash
# The notebooks automatically download the dataset from HuggingFace
# For manual setup:
python scripts/download_dataset.py
```

## ğŸ“ Repository Structure

```
neuralnetworks-final-project/
â”‚
â”œâ”€â”€ ğŸ““ Notebooks/
â”‚   â”œâ”€â”€ 1_cnn_model_notebook.ipynb          # CNN training and evaluation
â”‚   â”œâ”€â”€ 2_text_classification.ipynb         # F1-optimized text classifier  
â”‚   â””â”€â”€ 3_evaluation_multimodal.ipynb       # Comprehensive fusion evaluation
â”‚
â”œâ”€â”€ ğŸ§  Models/
â”‚   â”œâ”€â”€ cnn_architecture.py                 # ResNet50-based CNN implementation
â”‚   â”œâ”€â”€ text_classifier.py                  # F1-optimized BiLSTM with attention
â”‚   â”œâ”€â”€ fusion_strategies.py                # 8 multimodal fusion approaches
â”‚   â””â”€â”€ pattern_recognition.py              # Advanced harmful content patterns
â”‚
â”œâ”€â”€ ğŸ”§ Utils/
â”‚   â”œâ”€â”€ data_processing.py                  # Image and text preprocessing
â”‚   â”œâ”€â”€ evaluation.py                       # Performance metrics and analysis
â”‚   â”œâ”€â”€ visualization.py                    # Results plotting and visualization
â”‚   â””â”€â”€ ocr_text_removal.py                # Keras-OCR based text removal
â”‚
â”œâ”€â”€ ğŸ“Š Results/
â”‚   â”œâ”€â”€ figures/                            # Generated plots and visualizations
â”‚   â”œâ”€â”€ model_artifacts/                    # Trained models and preprocessors
â”‚   â”œâ”€â”€ evaluation_results.json             # Comprehensive evaluation metrics
â”‚   â””â”€â”€ fusion_comparison.csv               # Fusion strategy comparison
â”‚
â”œâ”€â”€ ğŸ“„ docs/
â”‚   â”œâ”€â”€ final_report.pdf                    # Complete academic paper
â”‚   â”œâ”€â”€ presentation.pdf                    # Project presentation
â”‚   â””â”€â”€ methodology.md                      # Detailed methodology
â”‚
â”œâ”€â”€ ğŸ› ï¸ scripts/
â”‚   â”œâ”€â”€ download_dataset.py                 # Dataset download utility
â”‚   â”œâ”€â”€ train_cnn.py                       # CNN training script
â”‚   â”œâ”€â”€ train_text.py                      # Text classifier training
â”‚   â””â”€â”€ evaluate_fusion.py                 # Fusion evaluation script
â”‚
â”œâ”€â”€ requirements.txt                        # Python dependencies
â”œâ”€â”€ environment.yml                         # Conda environment file
â””â”€â”€ README.md                              # This file
```

## ğŸ® Usage Examples

### 1. Train CNN Model
```python
# Load and run the CNN training notebook
jupyter notebook notebooks/1_cnn_model_notebook.ipynb

# Or use the script
python scripts/train_cnn.py --epochs 30 --batch_size 64 --lr 1e-5
```

### 2. Train Text Classifier with Optuna Optimization
```python
# F1-optimized text classifier with hyperparameter search
jupyter notebook notebooks/2_text_classification.ipynb

# Or use the script  
python scripts/train_text.py --trials 20 --optimize_f1
```

### 3. Evaluate Multimodal Fusion
```python
# Comprehensive evaluation of all fusion strategies
jupyter notebook notebooks/3_evaluation_multimodal.ipynb

# Or use the script
python scripts/evaluate_fusion.py --sample_size 1000 --strategies all
```
![evaluation_preformance](results/grpah_preformance_f1.png)

### 4. Quick Inference Example
```python
from models.cnn_architecture import HarmfulDetectionResnet50
from models.text_classifier import F1OptimizedHarmfulClassifier
from models.fusion_strategies import MultimodalFusion

# Load pre-trained models
cnn_model = HarmfulDetectionResnet50.load_pretrained('results/model_artifacts/cnn_model.pth')
text_model = F1OptimizedHarmfulClassifier.load_pretrained('results/model_artifacts/text_model.pth')

# Initialize fusion
fusion = MultimodalFusion(cnn_model, text_model, strategy='aggressive')

# Predict on new meme
image_path = 'path/to/meme_image.jpg'
meme_text = "extracted text from meme"

prediction, confidence = fusion.predict(image_path, meme_text)
print(f"Prediction: {'Harmful' if prediction else 'Safe'} (Confidence: {confidence:.3f})")
```

## ğŸ§ª Experimental Results

### Individual Component Performance
| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| **CNN (Image)** | 55.0% | 0.560 | 0.460 | **0.510** |
| **Text (F1-Opt)** | 64.3% | 0.765 | 0.036 | 0.068 |

### Fusion Strategy Comparison
| Strategy | Accuracy | Precision | Recall | F1-Score | Improvement |
|----------|----------|-----------|--------|----------|-------------|
| CNN Only | 55.0% | 0.560 | 0.460 | 0.510 | -- |
| **Aggressive Fusion** | **55.3%** | **0.548** | **0.482** | **0.514** | **+0.78%** |
| Conservative Fusion | 65.2% | 0.854 | 0.289 | 0.431 | -15.4% |
| Confidence Winner | 54.8% | 0.558 | 0.454 | 0.502 | -1.57% |
| Adaptive Weighted | 55.1% | 0.561 | 0.462 | 0.508 | -0.39% |

## ğŸ”¬ Technical Innovations

### 1. F1-Optimized Loss Function
```python
def f1_loss(logits, targets, epsilon=1e-7):
    """Direct F1 optimization through differentiable approximation"""
    ce_loss = nn.CrossEntropyLoss()(logits, targets)
    
    # Soft F1 calculation
    probs = torch.softmax(logits, dim=1)[:, 1]
    tp = torch.sum(probs * targets.float())
    fp = torch.sum(probs * (1 - targets.float()))
    fn = torch.sum((1 - probs) * targets.float())
    
    precision = tp / (tp + fp + epsilon)
    recall = tp / (tp + fn + epsilon)
    f1 = 2 * precision * recall / (precision + recall + epsilon)
    
    return ce_loss - torch.log(f1 + epsilon)
```

### 2. Hierarchical Attention Mechanism
- Word-level attention with learnable context vectors
- Provides explainable predictions for content moderation
- 0.78 correlation with human-annotated harmful spans

### 3. Advanced Pattern Recognition
- **Coded Language Detection**: Dogwhistles, euphemisms, statistical racism
- **Context Analysis**: Negation handling, question vs. statement analysis  
- **Severity Weighting**: Graduated harm scoring (violence=10, identity attacks=9)
- **Multi-level Features**: 30+ linguistic patterns across harmful categories

### 4. Comprehensive Fusion Evaluation
- **8 Fusion Strategies**: From conservative to aggressive approaches
- **Statistical Validation**: Paired t-tests with cross-validation
- **Confidence Calibration**: Normalized uncertainty across modalities

## ğŸ“ˆ Performance Analysis

### CNN Training Dynamics
![CNN Training](results/Images_Train_Valid_Acc_New.png)

### Fusion Strategy Comparison
![Fusion Comparison](results/Images_CNN_New.png)

### Error Analysis Examples
| False Positives | False Negatives |
|----------------|-----------------|
| ![FP](results/figures/Images_False_Positive_Sample_New.png) | ![FN](results/figures/Images_False_Negative_Sample_New.png) |

## âš¡ Hardware Requirements

### Minimum Requirements
- **GPU**: 8GB VRAM (GTX 1080 / RTX 2070 equivalent)
- **RAM**: 16GB system memory
- **Storage**: 10GB free space
- **Time**: ~6 hours total training time

### Recommended Setup
- **GPU**: 16GB VRAM (T4, RTX 3080, V100)
- **RAM**: 32GB system memory  
- **Storage**: 50GB SSD space
- **Platform**: Google Colab Pro, Databricks, or dedicated GPU server

## ğŸš§ Known Issues & Limitations

### Current Limitations
1. **Text Component Overfitting**: Severe validation-test gap (F1: 0.761 â†’ 0.068)
2. **Resolution Constraints**: Limited to 128Ã—128 due to memory constraints
3. **Ground Truth Quality**: ChatGPT-generated labels may contain biases
4. **Binary Classification**: Real harmful content exists on spectrum

### Future Improvements
- [ ] **Higher Resolution**: Implement efficient processing for 224Ã—224+ images
- [ ] **Better Text Generalization**: Address overfitting through regularization
- [ ] **Multi-class Classification**: Granular harm type detection
- [ ] **Cross-platform Evaluation**: Test on diverse social media content
- [ ] **Real-time Optimization**: Reduce inference latency for production

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Setup
```bash
# Create development environment
conda env create -f environment.yml
conda activate harmful-content-detection

# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
pytest tests/

# Format code
black . && flake8 .
```

## ğŸ“š Academic Paper & Citation

This work is documented in our comprehensive academic paper. If you use this code or methodology, please cite:

```bibtex
@article{cohen2025multimodal,
  title={Multimodal Harmful Content Detection in Social Media Memes},
  author={Cohen, Stav and Pecani, Efi},
  journal={Deep Learning Final Project - Reichman University},
  year={2025},
  url={https://github.com/stavco9/neuralnetworks-final-project}
}
```

**Paper Highlights**:
- Novel F1-optimized text classification architecture
- Systematic evaluation of 8 multimodal fusion strategies  
- Advanced pattern recognition for coded language detection
- Production-ready implementation with comprehensive evaluation

## ğŸ† Project Achievements

- âœ… **Academic Excellence**: Comprehensive methodology with rigorous evaluation
- âœ… **Technical Innovation**: F1-optimized loss and hierarchical attention
- âœ… **Systematic Analysis**: 8 fusion strategies with statistical validation
- âœ… **Production Ready**: Scalable architecture with deployment considerations
- âœ… **Open Source**: Complete codebase with reproducible results
- âœ… **Documentation**: Detailed paper and implementation guides

## ğŸ‘¥ Authors

| Author | Role | Contact |
|--------|------|---------|
| **Stav Cohen** | CNN Architecture, Image Processing, Evaluation | [stav.cohen](mailto:stav.cohen9@ost.runi.ac.il) |
| **Efi Pecani** | Text Classification, Fusion Strategies, Optimization | [efraim.pecani](mailto:efraim.pecani@post.runi.ac.il) |

*Computer Science M.Sc. Students*  
*Reichman University, Israel*

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Reichman University** - Deep Learning Course & Computational Resources
- **Facebook Research** - Hateful Memes Challenge inspiration
- **HuggingFace** - Dataset hosting and community support
- **PyTorch Team** - Deep learning framework
- **Google Colab** - Training infrastructure
- **Databricks** - Advanced GPU resources

---

<div align="center">

**â­ Star this repository if you find it useful! â­**

*Building safer online communities through advanced AI*

[ğŸ“Š Results](#-experimental-results) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“„ Paper](docs/final_report.pdf) â€¢ [ğŸ› Issues](https://github.com/stavco9/neuralnetworks-final-project/issues)

</div>
